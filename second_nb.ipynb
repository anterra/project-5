{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tensorflow",
   "display_name": "tensorflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sklearn\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "KERAS_BACKEND=tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.3.0'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vinyasa Krama\n",
    "What follows is my development of the proof-of-concept prototype for an app called Vinyasa Krama, an app which generates complete, well-structured, safe and compelling yoga sequences, via a bi-directional LSTM. In this app, the user is able to pick a desired 'peak' pose -- this is generally the most difficult posture located in the middle of a yoga class, and a custom class will be generated for them which will proper warm them up for and cool them down from that pose, properly preparing the relevant muslces and joints. The class is hence generated from the middle out. They can then take the class, and follow along with an animated yoga teacher (created in the Unity game engine) who will demonstrate the class pose by pose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading In Yoga Class Data\n",
    "\n",
    "Most of these DataFrames were scraped and created during my previous project, \"Yoga Class-ification\", with the exception of vinaysa_df and hatha_df, which I scraped to supplement my existent data to have a larger dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"all_poses\", \"rb\")\n",
    "all_poses = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"flask_app_df\", \"rb\")\n",
    "poses_info = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"all_yoga_classes_df\", \"rb\")\n",
    "yoga_classes = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"poses_df\", \"rb\")\n",
    "class_poses = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"vinyasa_df\", \"rb\")\n",
    "more_vinyasa = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"hatha_df\", \"rb\")\n",
    "more_hatha = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataFrames and Excluding Restorative Class Types\n",
    "I am excluding the classes that are of type \"gentle\", \"restorative\" and \"yin\", as these are very slow restorative/laying down type classes that I'm not aiming to create (yet) with this app. I want more dynamic, flow and exercise based classes to be generated, plus I have much more data availble in support of creating those types.\n",
    "\n",
    "Furthermore, I want the LSTM to have rather consistent classes it's being trained on so it can best understand the sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([yoga_classes, more_vinyasa, more_hatha])\n",
    "df = df.loc[df[\"Class Type\"].isin([\"Vinyasa\", \"Hatha\", \"Power\", \"Iyengar\", \"Ashtanga\"])]\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   index                               Title  \\\n0      0    ←Slow Sunday Flow y Monday early   \n1      1                           ←Anahata    \n2      2                               ←CORE   \n3      3                                   ←   \n4      4  ←Vinyasa - Bench press & push up #   \n\n                                               Poses Class Type  \n0  [Easy Pose Hands To Heart, Easy Pose Hands Int...    Vinyasa  \n1  [Mantra Section, Thunderbolt Pose, Easy Pose B...    Vinyasa  \n2  [Classic Sun Salutation Variation F, Chair Pos...    Vinyasa  \n3  [Easy Pose, Easy Pose Warm Up Flow, Sun Saluta...    Vinyasa  \n4  [Corpse Pose, Corpse Pose Roll Under Spine, Wr...    Vinyasa  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Title</th>\n      <th>Poses</th>\n      <th>Class Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>←Slow Sunday Flow y Monday early</td>\n      <td>[Easy Pose Hands To Heart, Easy Pose Hands Int...</td>\n      <td>Vinyasa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>←Anahata</td>\n      <td>[Mantra Section, Thunderbolt Pose, Easy Pose B...</td>\n      <td>Vinyasa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>←CORE</td>\n      <td>[Classic Sun Salutation Variation F, Chair Pos...</td>\n      <td>Vinyasa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>←</td>\n      <td>[Easy Pose, Easy Pose Warm Up Flow, Sun Saluta...</td>\n      <td>Vinyasa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>←Vinyasa - Bench press &amp; push up #</td>\n      <td>[Corpse Pose, Corpse Pose Roll Under Spine, Wr...</td>\n      <td>Vinyasa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Yoga Poses\n",
    "I am concatenating together all of the yoga classes into one long list of lists to be fed to a neural net.\n",
    "\n",
    "I am keeping these as lists, rather than one continuous string, because I want each individual pose to be a token -- if concatenating, NLP methods of tokenization would require I split on white space or some other arbitrary character, which would lose meaning. Instead, I am keeping each pose as an item inside a list, to preserve the meaning of the entire pose name (usually multiple words long) in each token. \n",
    "\n",
    "I am also reducing all of the 3600+ yoga pose variations down to their base poses. Many of the variations are not very distinct from one another, and for the sake of this MVP, the neural net will have richer context for fewer words seen more often, than thousands of different words -- it would not make sense to approach this problem that way, especially since the poses are in fact so similar. \n",
    "\n",
    "I, using industry knowledge, am adjusting from the 102 original base poses in my data, to include a few key variations which actually are distinct and represent different body movements. In this way I am not oversimplifying either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [class_list for class_list in df[\"Poses\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_poses = poses_info[[\"Pose Name\", \"Base Pose\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting this out for readability but I manually looked at every pose in order to create the following...\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# base_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = [([4, 17, 47, 50, 60], \"Cycling Pose\"),\n",
    "    ([19, 40, 41, 44, 46, 28, 54, 67, 68, 72], \"High Boat To Low Boat Flow\"),\n",
    "    ([64, 66, 69, 70], \"Low Boat Pose\"),\n",
    "    ([86], \"Staff Pose\"), \n",
    "    ([87, 88, 117, 118], \"Bound Angle Forward Bend\"), \n",
    "    ([125, 135, 136, 138, 140, 141], \"One Legged Bow Pose\"), \n",
    "    ([216, 217, 218, 219], \"Pigeon Pose\"), \n",
    "    ([233, 234, 235, 236, 237, 238, 239], \"Thunderbolt Pose\"), \n",
    "    ([248, 269, 270, 271, 274], \"Cow Pose\"), \n",
    "    ([259, 260, 261, 262, 263, 364, 265, 266, 267, 268, 272, 273, 275], \"Cat Pose\"),\n",
    "    ([291], \"Hurdlers Pose\"),\n",
    "    ([293, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 372], \"Revolved Chair Pose\"), \n",
    "    ([300, 303, 306, 307, 308], \"Chair Pose With Airplane Arms\"),\n",
    "    ([365, 369, 370], \"Figure Four Pose\"), \n",
    "    ([368], \"Shiva Squat Pose\"), \n",
    "    ([520, 521], \"Supine Spinal Twist Pose\"), \n",
    "    ([587, 588], \"Flying Pigeon Pose\"), \n",
    "    ([594, 589], \"Side Crow Pose\"), \n",
    "    ([599], \"Baby Crow Pose\"), \n",
    "    ([663, 664, 665, 666, 667, 668], \"One Legged Mountain Pose\"), \n",
    "    ([687, 758], \"One Handed Downward Facing Dog Pose\"),\n",
    "    ([688, 689, 690, 759, 760], \"Standing Splits Pose\"), \n",
    "    ([691, 692, 693, 694, 724, 735, 736, 737, 761, 762, 763, 764], \"Three Legged Downward Facing Dog Pose\"), \n",
    "    ([700, 717], \"Downward Facing Dog Upward Facing Dog Pose Flow\"), \n",
    "    ([714], \"Downward Facing Dog Pose Plank Pose Flow\"), \n",
    "    ([715], \"Downward Facing Dog Pose Table Top Pose Flow\"), \n",
    "    ([747], \"Downward Facing Dog Pose Knee To Nose\"),\n",
    "    ([748], \"Downward Facing Dog Pose Shoulder Taps\"), \n",
    "    ([749], \"Downward Facing Dog Pose to Low Lunge Pose Flow\"), \n",
    "    ([865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901], \"Easy Pose\"), \n",
    "    ([924, 925, 926], \"\"), # this was \"cactus arms\", its a variation that won't make sense in most contexts. intentionally deleting this and will filter out empty strings upon generation. \n",
    "    ([998], \"Half Lotus Pose\"), \n",
    "    ([999], \"Lotus Pose\"), \n",
    "    ([1016, 1017], \"Eye Exercise\"), ([1055, 1056, 1057, 1058, 1061], \"Scorpion Pose\"), \n",
    "    ([1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151], \"Chaturanga Dandasana\"),\n",
    "    ([1387], \"Headstand Pose Eagle Legs\"), \n",
    "    ([1390], \"Headstand Pose Lotus Legs\"), \n",
    "    ([1392], \"Headstand Pose Wide Legs\"), \n",
    "    ([1395, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407], \"Tripod Headstand Pose\"), \n",
    "    ([1464, 1465, 1479, 1480, 1481, 1482], \"Revolved High Lunge Pose\"), \n",
    "    ([1466, 1467, 1468, 1469, 1483], \"Runners Lunge Pose\"), \n",
    "    ([1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533], \"Wide Legged Forward Fold\"), \n",
    "    ([1487, 1509, 1510, 1511, 1512], \"Revolved Wide Legged Forward Fold\"),\n",
    "    ([1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498], \"Wide Legged Forward Fold With Halfway Lift\"),\n",
    "    ([1489, 1490, 1527], \"Five Pointed Star Pose\"), \n",
    "    ([1508], \"Pyramid Pose\"), \n",
    "    ([1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566], \"Pyramid Pose\"), \n",
    "    ([1584], \"Flying Lizard Pose\"), \n",
    "    ([1673, 1684, 1685, 1591, 1700, 1708, 1710, 1711, 1712], \"Revolved Low Lunge Pose\"),\n",
    "    ([1732, 1733, 1745, 1758, 1758, 1776, 1777, 1778, 1784, 1790, 1791, 1791], \"One Legged Moutain Pose\"), \n",
    "    ([1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852], \"Easy Pose\"), \n",
    "    ([1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882], \"Standing Side Bend Pose\"), \n",
    "    ([1891, 1892, 1893, 1901, 1901, 1903, 1904, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922], \"King Pigeon Pose\"), \n",
    "    ([1927, 1928, 1932], \"Grasshopper Pose\"), \n",
    "    ([1929], \"Dragonfly Pose\"), \n",
    "    ([1930], \"Eight Angle Pose\"),\n",
    "    ([1934, 1970, 1971, 1972], \"One Legged Plank Pose\"), ([1939], \"Side Plank Pose\"), \n",
    "    ([1958, 1959, 1960, 1961, 1967, 1968, 1969], \"Forearm Plank Pose\"), \n",
    "    ([2173], \"Lotus Pose\"), \n",
    "    ([2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200], \"Revolved Extended Side Angle Pose\"), \n",
    "    ([2189, 2195, 2196], \"Revolved High Lunge Pose\"), \n",
    "    ([2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368], \"Skandasana\"),\n",
    "    ([2390, 2397], \"Anantasana\"), \n",
    "    ([2415, 2416, 2417, 2418, 2419, 2420, 2443], \"Visvamitrasana Pose\"), \n",
    "    ([2422, 2427, 2428, 2430, 2431, 2433, 2453, 2458, 2460], \"Side Plank Pose With Leg Variation\"), \n",
    "    ([2436, 2437, 2438, 2439, 2440, 2441], \"Forearm Side Plank Pose\"), \n",
    "    ([2465, 2466], \"Wild Thing Pose\"), \n",
    "    ([2482, 2483, 2484, 2486, 2487, 2488, 2489, 2480, 2492, 2493], \"Half Splits Pose\"), \n",
    "    ([2494], \"Standing Splits Pose\"), \n",
    "    ([2592, 2593, 2594], \"Firefly Pose\"), \n",
    "    ([2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621], \"Forward Fold Pose With Halfway Lift\"), \n",
    "    ([2688, 2689, 2692, 2717], \"Bird Of Paradise Pose\"), \n",
    "    ([2700, 2701, 2703], \"Revolved Hand To Big Toe Pose\"), \n",
    "    ([2750, 2758], \"Half Sun Salutation\"), \n",
    "    ([2759], \"Second Half Of Sun Salutation\"), \n",
    "    ([2771, 2772], \"Banana Pose\"), \n",
    "    ([2795], \"Supine Spinal Twist Pose\"), \n",
    "    ([2797, 2798, 2833, 2848, 2849, 2850], \"Tiger Pose\"), \n",
    "    ([2799, 2816, 2827], \"Table Top Knee To Nose Flow\"), \n",
    "    ([2800, 2817], \"Child Pose Table Top Pose Flow\"), \n",
    "    ([2801, 2831, 2834, 2837, 2840, 2841, 2842], \"Table Top Pose With One Leg Extended Back\"), \n",
    "    ([2809, 2810, 2811, 2812, 2813, 2814, 2815], \"Revolved Table Top Pose\"), \n",
    "    ([2852, 2853, 2854, 2855], \"Table Top Balancing Pose, Opposite Arm and Leg Extended\"), \n",
    "    ([2968, 2972, 2983, 2974, 2975, 2976, 2977, 3005, 3006, 3007, 3008], \"Revolved Triangle Pose\"), \n",
    "    ([3023, 3024, 3025, 3026, 3031, 3032, 3038, 3039, 3040], \"Reverse Table Top Pose\"), \n",
    "    ([3037], \"Flip The Dog Pose\"), \n",
    "    ([3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063], \"Anantasana\"), \n",
    "    ([3064, 3065, 3066, 3067, 3070, 3071, 3072, 3073, 3074, 3075, 3079], \"Warrior Pose I\"), \n",
    "    ([3068, 3069, 3076, 3077, 3078], \"Humble Warrior Pose\"), \n",
    "    ([3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121], \"Warrior Pose II\"), \n",
    "    ([3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144], \"Warrior Pose III\"), \n",
    "    ([3134], \"Shiva Squat Pose\"), \n",
    "    ([3131, 3132, 3133], \"Airplane Pose\"), \n",
    "    ([3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190], \"Half Wind Release Pose\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in changes:\n",
    "    base_poses.loc[i[0], \"Base Pose\"] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "170"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(base_poses[\"Base Pose\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know have 170 distinct poses that I will be feeding to my neural net. Now creating a list of class data to feed to the neural net out of the base documents only:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_documents = []\n",
    "for i in range(len(documents)):\n",
    "    temp_df = pd.DataFrame(documents[i], columns=[\"0\"])\n",
    "    temp_df = pd.merge(temp_df, base_poses, how=\"left\", left_on=\"0\", right_on=\"Pose Name\")\n",
    "    temp_df = temp_df.dropna(how=\"any\")\n",
    "    new_doc = [pose for pose in temp_df[\"Base Pose\"]]\n",
    "    base_documents.append(new_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Start and End Poses\n",
    "For the sake of class generation, since generation is starting with the user's desired most difficult pose in the middle of the class, I want the classes to not be generated to some arbitary pre-set length, but instead continue generating until converging to the natural start and end yoga poses of a class. Hence I am finding the most common start and end poses across all classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_poses = []\n",
    "for doc in base_documents:\n",
    "    if doc:\n",
    "        first_poses.append(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_poses = []\n",
    "for doc in base_documents:\n",
    "    if doc:\n",
    "        last_poses.append(doc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Easy Pose : 12182\nThunderbolt Pose : 743\nSun Salutation : 1764\nCorpse Pose : 5272\nTable Top Pose : 669\nLotus Pose : 433\nPranayama : 2099\nReclined Bound Angle Pose : 1207\nChild Pose : 2534\nCycling Pose : 326\n"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(list(Counter(first_poses).keys())[i], \":\", list(Counter(first_poses).values())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Corpse Pose : 20486\nSide Lying Corpse Pose : 637\nDownward Facing Dog Pose : 684\nThunderbolt Pose : 193\nHalf Sun Salutation : 49\nThread The Needle Pose : 117\nRevolved Wide Legged Forward Fold : 32\nBridge Pose : 630\nPranayama : 971\nChair Pose : 280\n"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(list(Counter(last_poses).keys())[i], \":\", list(Counter(last_poses).values())[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of classes begin with easy pose (simple cross-legged seat, often for meditation). Pranayama which is also very high just means \"breathing\", which is not itself a \"pose\", but a breath technique which would commonly practiced while in sitting meditation (easy pose). By far the most common last pose is 'corpse pose', or final savasana, lying down meditation. \n",
    "\n",
    "Without even having done the above exploration, I would have been inclined to start the classes with 'easy pose' and end with 'corpse' pose just due to my personal experience with yoga, but now I have the empirical evidence to support that decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embeddings\n",
    "I am using a custom word embedding model to find similarities between poses. I will then implement transfer learning, using this pre-trained word embedding model as my initial weights for the LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = gensim.models.Word2Vec(base_documents, size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "169"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "embeddings_size = len(list(embeddings.wv.vocab.items()))\n",
    "embeddings_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Embedding Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.098134644\n0.1699742\n0.39498302\n0.81561786\n"
    }
   ],
   "source": [
    "print(embeddings.similarity(\"Corpse Pose\", \"Dancer Pose\"))\n",
    "print(embeddings.similarity(\"Corpse Pose\", \"Extended Side Angle Pose\"))\n",
    "print(embeddings.similarity(\"Corpse Pose\", \"Child Pose\"))\n",
    "print(embeddings.similarity(\"Corpse Pose\", \"Wind Release Pose\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above looks very accurate. When compared to 'corpse pose', which is lying down meditation, model indicates very little similarity to difficulty balancing and strength-heavy standing poses, mild similarity to an intense prone stretch pose, moderate similarity to a relaxation prone pose, and very high similarity to wind release pose, which often tends to be practiced immediately before corpse pose, and is also very easy and practiced while laying on the back. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(worda, wordb, wordc):\n",
    "    result = embeddings.most_similar(negative=[worda], positive=[wordb, wordc])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Table Top Balancing Pose, Opposite Arm and Leg Extended'"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "analogy(\"Downward Facing Dog Pose\", \"Three Legged Downward Facing Dog Pose\", \"Table Top Pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Palm Tree Pose'"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "analogy(\"Warrior Pose II\", \"Extended Side Angle Pose\", \"Mountain Pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Chair Pose'"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "analogy(\"Revolved Triangle Pose\", \"Triangle Pose\", \"Revolved Chair Pose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analogies also indicate that the embeddings model has picked up a good deal of nuanced meaning about the poses. When down dog to a balancing version of downdog is compared to table top, it offers a balancing version of table top. When an arms extended version of warrior II is compared to mountain pose, it offers an arms extended version of mountain (palm tree). When a revolved version of triangle and regular triangle is compared to a revolved version of chair, it offers regular chair. Wonderful! \n",
    "\n",
    "Saving the embeddings as a matrix for use in the neural net: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(embeddings.wv.vocab)+1, 100))\n",
    "for i in range(len(embeddings.wv.vocab)):\n",
    "    embedding_vector = embeddings.wv[embeddings.wv.index2word[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = embeddings.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-Directional LSTM Neural Network\n",
    "\n",
    "## Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total tokens:  1624681\nUnique tokens:  169\n"
    }
   ],
   "source": [
    "tokens = [pose for yogaclass in base_documents for pose in yogaclass]\n",
    "print(\"Total tokens: \", len(tokens))\n",
    "print(\"Unique tokens: \", len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Sequences\n",
    "I am training the network on an input sequence length of 3 poses, where it will then learn the expected fourth pose. This small input sequence length size is ideal for seeing all the poses in many many contexts, and allows for easy generation from a selected single base pose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Sequences: 1624677\n"
    }
   ],
   "source": [
    "length = 3 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    seq = tokens[i-length:i]\n",
    "    sequences.append(seq)\n",
    "print(\"Total Sequences:\", len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Vocab Size: 170\n"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "token_sequences = tokenizer.texts_to_sequences(sequences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocab Size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray([np.asarray(x[:-1]) for x in token_sequences])\n",
    "y = [y[-1] for y in token_sequences]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length=len(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Architecture \n",
    "My choice of deep learning model is a bi-directional LSTM. This is the ideal choice for my purposes. \n",
    "\n",
    "Long Short-Term Memory NNs are considered the best performing models for sequence prediction, and are excellent for text generation -- and I am, in this project, doing both. I am generating text that is a sequence of yoga poses that should go in a fairly specific order in order to be safe and comprise a good class. \n",
    "\n",
    "A bi-directional LSTM is an even more ideal choice -- Since I am generating my classes from the middle (peak pose) out, I essentially need to predict and generate half of the from the peak to the end in a forward direction, and the other half of the sequence from the peak to the beginning in a backwards direction. A bi-directional LSTM is uniquely poised to allow me to do this -- by providing the input sequence to each layer twice, once as is and once reversed, and then concatenating the outputs -- the msdel has twice as much context about each pose, and is then able to predict what pose would *precede* a given sequence, as well as follow it. \n",
    "\n",
    "I have chosen after some experimentation to use 3 hidden bidirectional LSTM layers, with dropout layers between each, of a size roughly comparable to my vocabulary. I then have 2 activation layers, the first using RELU and the second softmax as any form of sequence/text prediction is categorized as a multi-class classification problem. \n",
    "\n",
    "I train the model with a modest batch size of 128 (given the 1.6mil input sequences), over 100 epochs, using the adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False))\n",
    "    model.add(Bidirectional(LSTM(200, return_sequences=True)))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Bidirectional(LSTM(200, return_sequences=True)))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Bidirectional(LSTM(200)))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(100, activation=\"relu\"))\n",
    "    model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X, y):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X, y, batch_size=128, epochs=100, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, None, 100)         17000     \n_________________________________________________________________\nbidirectional_3 (Bidirection (None, None, 400)         481600    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, None, 400)         0         \n_________________________________________________________________\nbidirectional_4 (Bidirection (None, None, 400)         961600    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, None, 400)         0         \n_________________________________________________________________\nbidirectional_5 (Bidirection (None, 400)               961600    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 400)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 100)               40100     \n_________________________________________________________________\ndense_3 (Dense)              (None, 170)               17170     \n=================================================================\nTotal params: 2,479,070\nTrainable params: 2,462,070\nNon-trainable params: 17,000\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "lstm_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\nEpoch 2/100\nEpoch 3/100\nEpoch 4/100\nEpoch 5/100\nEpoch 6/100\nEpoch 7/100\nEpoch 8/100\nEpoch 9/100\nEpoch 10/100\nEpoch 11/100\nEpoch 12/100\nEpoch 13/100\nEpoch 14/100\nEpoch 15/100\nEpoch 16/100\nEpoch 17/100\nEpoch 18/100\nEpoch 19/100\nEpoch 20/100\nEpoch 21/100\nEpoch 22/100\nEpoch 23/100\nEpoch 24/100\nEpoch 25/100\nEpoch 26/100\nEpoch 27/100\nEpoch 28/100\nEpoch 29/100\nEpoch 30/100\nEpoch 31/100\nEpoch 32/100\nEpoch 33/100\nEpoch 34/100\nEpoch 35/100\nEpoch 36/100\nEpoch 37/100\nEpoch 38/100\nEpoch 39/100\nEpoch 40/100\nEpoch 41/100\nEpoch 42/100\nEpoch 43/100\nEpoch 44/100\nEpoch 45/100\nEpoch 46/100\nEpoch 47/100\nEpoch 48/100\nEpoch 49/100\nEpoch 50/100\nEpoch 51/100\nEpoch 52/100\nEpoch 53/100\nEpoch 54/100\nEpoch 55/100\nEpoch 56/100\nEpoch 57/100\nEpoch 58/100\nEpoch 59/100\nEpoch 60/100\nEpoch 61/100\nEpoch 62/100\nEpoch 63/100\nEpoch 64/100\nEpoch 65/100\nEpoch 66/100\nEpoch 67/100\nEpoch 68/100\nEpoch 69/100\nEpoch 70/100\nEpoch 71/100\nEpoch 72/100\nEpoch 73/100\nEpoch 74/100\nEpoch 75/100\nEpoch 76/100\nEpoch 77/100\nEpoch 78/100\nEpoch 79/100\nEpoch 80/100\nEpoch 81/100\nEpoch 82/100\nEpoch 83/100\nEpoch 84/100\nEpoch 85/100\nEpoch 86/100\nEpoch 87/100\nEpoch 88/100\nEpoch 89/100\nEpoch 90/100\nEpoch 91/100\nEpoch 92/100\nEpoch 93/100\nEpoch 94/100\nEpoch 95/100\nEpoch 96/100\nEpoch 97/100\nEpoch 98/100\nEpoch 99/100\nEpoch 100/100\n"
    }
   ],
   "source": [
    "fit_model(lstm_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = load_model('lstm_model.h5', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yoga Class Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class(model, tokenizer, word_embedding, peak_pose, stop_pose, max_length):\n",
    "\n",
    "    # generate seed text of 3 poses (as LSTM was trained on) from the input desired peak pose, by randomly selecting two of the most similar poses to the peak. \n",
    "    seed_text = [peak_pose, embeddings.most_similar(peak_pose, topn=10)[np.random.choice(range(10))][0], embeddings.most_similar(peak_pose, topn=10)[np.random.choice(range(10))][0]]\n",
    "    in_text = seed_text\n",
    "\n",
    "    # create yoga class, and make sure it includes the user's desired peak pose\n",
    "    yoga_class = list()\n",
    "    first_half = list()\n",
    "    second_half = list()\n",
    "    yoga_class.append(peak_pose.lower())\n",
    "\n",
    "    while True:\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])\n",
    "\n",
    "        # select next pose based on models probability distribution\n",
    "        prediction_output = model.predict(encoded)\n",
    "        yhat = np.random.choice(len(prediction_output[0]), p=prediction_output[0])\n",
    "        # argsort version:\n",
    "        # predictions = np.argsort(model.predict(encoded), axis=-1)[-10:][::-1]\n",
    "        # yhat = np.random.choice(predictions[0])\n",
    "\n",
    "        out_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        \n",
    "        # append pose to current class, and update input text\n",
    "        # also add clarification text for user to repeat the pose on the other side (if its an imbalanced pose) if given two of the same pose in a row\n",
    "        if out_word != \"\":\n",
    "            if out_word == yoga_class[-1]:\n",
    "                in_text.append(out_word)\n",
    "                out_word += \", repeat other side\"\n",
    "                yoga_class.append(out_word)\n",
    "            else: \n",
    "                yoga_class.append(out_word)\n",
    "                in_text.append(out_word)\n",
    "        if out_word == stop_pose:\n",
    "            break\n",
    "\n",
    "        # if sequence gets too long without converging to a natural ending, start over. \n",
    "        if len(yoga_class) == max_length:\n",
    "                in_text = seed_text\n",
    "                yoga_class = [peak_pose.lower()]\n",
    "    return yoga_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_peak_poses = ['Center Splits Pose', 'Hurdlers Pose', 'Revolved Chair Pose', 'Figure Four Pose', 'Crane Pose', 'Flying Pigeon Pose', 'Side Crow Pose', 'Baby Crow Pose', 'Crow Pose', 'Dancer Pose', 'Eagle Pose', 'Feathered Peacock Pose', 'Scorpion Pose', 'Flamingo Pose', 'Foot Behind The Head Pose', 'Half Moon Pose', 'Handstand Pose', 'Headstand Pose', 'Headstand Pose Eagle Legs', 'Headstand Pose Lotus Legs', 'Headstand Pose Wide Legs', 'Tripod Headstand Pose', 'Revolved High Lunge Pose', 'Pyramid Pose', 'Flying Lizard Pose', 'Palm Tree Pose', 'King Pigeon Pose', 'Grasshopper Pose', 'Dragonfly Pose', 'Eight Angle Pose', 'Revolved Extended Side Angle Pose', 'Visvamitrasana Pose', 'Wild Thing Pose', 'Splits Pose', 'Firefly Pose', 'Bird Of Paradise Pose', 'Standing Hand To Big Toe Pose', 'Revolved Hand To Big Toe Pose', 'Tree Pose', 'Revolved Triangle Pose', 'Triangle Pose', 'Flip The Dog Pose', 'Warrior Pose I', 'Humble Warrior Pose', 'Warrior Pose II', 'Warrior Pose III', 'Airplane Pose', 'Wheel Pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"peak_poses.pkl\", \"wb\")\n",
    "pickle.dump(possible_peak_poses, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_pose = np.random.choice(possible_peak_poses)\n",
    "peak_pose = 'Flying Pigeon Pose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['humble warrior pose', 'child pose', 'downward facing dog pose', 'mountain pose', 'half lord of the fishes pose', 'standing forward fold pose', 'cycling pose', 'seated forward bend pose', 'eagle pose', 'mountain pose', 'mountain pose, repeat other side', 'thunderbolt pose', 'thunderbolt pose, repeat other side', 'child pose', 'child pose, repeat other side', 'lotus pose', 'bound angle pose', 'half lord of the fishes pose', 'corpse pose']\n\n\n['palm tree pose', 'mountain pose', 'palm tree pose', 'palm tree pose, repeat other side', 'shoulder stretches', 'standing twists', 'chair pose', 'chair pose, repeat other side', 'head to knee pose', 'thunderbolt pose', 'torso stretch pose', 'easy pose', 'easy pose, repeat other side', 'half lord of the fishes pose', 'torso stretch pose', 'seated straddle pose', 'happy baby pose', 'reclined big toe pose', 'bridge pose', 'half lord of the fishes pose', 'pranayama', 'pranayama, repeat other side', 'sun salutation', 'standing forward fold pose', 'corpse pose']\n\n\n['flying lizard pose', 'crane pose', 'wide legged forward fold', 'lizard pose', 'legs up the wall pose', 'plank pose', 'upward plank pose', 'standing hand to big toe pose', 'bridge pose', 'happy baby pose', 'banana pose', 'mountain pose', 'supine spinal twist pose', 'shoulderstand pose', 'chair pose', 'mountain pose', 'corpse pose']\n\n\n['revolved extended side angle pose', 'shoulderstand pose', 'reclined bound angle pose', 'bound angle pose', 'half lord of the fishes pose', 'bound angle forward bend', 'chair pose', 'garland pose', 'wind release pose', 'table top pose', 'half lord of the fishes pose', 'tree pose', 'supine spinal twist pose', 'staff pose', 'bound angle pose', 'bound angle pose, repeat other side', 'bound angle pose', 'wind release pose', 'wind release pose, repeat other side', 'half lord of the fishes pose', 'supine spinal twist pose', 'corpse pose']\n\n\n['tripod headstand pose', 'headstand pose', 'headstand pose, repeat other side', 'headstand pose', 'headstand pose, repeat other side', 'headstand pose', 'child pose', 'child pose, repeat other side', 'wind release pose', 'corpse pose']\n\n\n['bird of paradise pose', 'warrior pose iii', 'triangle pose', 'triangle pose, repeat other side', 'triangle pose', 'triangle pose, repeat other side', 'revolved triangle pose', 'revolved triangle pose, repeat other side', 'revolved triangle pose', 'triangle pose', 'revolved triangle pose', 'triangle pose', 'revolved triangle pose', 'revolved triangle pose, repeat other side', 'triangle pose', 'easy pose', 'bound angle pose', 'staff pose', 'plank pose', 'table top pose', 'pigeon pose', 'staff pose', 'bound angle pose', 'bridge pose', 'corpse pose']\n\n\n['pyramid pose', 'fish pose', 'cow face pose', 'bound angle forward bend', 'bound angle pose', 'bound angle pose, repeat other side', 'seated forward bend pose', 'eye of the needle pose', 'half lord of the fishes pose', 'bound angle pose', 'chair pose', 'corpse pose']\n\n\n['foot behind the head pose', 'pigeon pose', 'easy pose', 'sphinx pose', 'happy baby pose', 'seated forward bend pose', 'wild thing pose', 'half lord of the fishes pose', 'supine spinal twist pose', 'happy baby pose', 'locust pose', 'boat pose', 'cow face pose', 'child pose', 'half lord of the fishes pose', 'easy pose', 'seated forward bend pose', 'child pose', 'standing side bend pose', 'chair pose', 'warrior pose i', 'warrior pose ii', 'easy pose', 'downward facing dog pose', 'boat pose', 'easy pose', 'half lord of the fishes pose', 'chair pose', 'boat pose', 'bridge pose', 'bound angle pose', 'eye of the needle pose', 'downward facing dog pose', 'wind release pose', 'shoulderstand pose', 'half wind release pose', 'happy baby pose', 'corpse pose']\n\n\n['revolved high lunge pose', 'splits pose', 'downward facing dog pose knee to nose', 'plank pose', 'plank pose, repeat other side', 'plank pose', 'downward facing dog pose', 'pyramid pose', 'revolved high lunge pose', 'child pose', 'downward facing dog pose', 'wide legged forward fold', 'pyramid pose', 'half moon pose', 'half moon pose, repeat other side', 'seated straddle pose', 'camel pose', 'bridge pose', 'corpse pose']\n\n\n['humble warrior pose', 'revolved hand to big toe pose', 'standing hand to big toe pose', 'warrior pose iii', 'mountain pose', 'standing hand to big toe pose', 'warrior pose iii', 'warrior pose iii, repeat other side', 'half moon pose', 'half moon pose, repeat other side', 'sun salutation', 'side plank pose', 'tree pose', 'revolved hand to big toe pose', 'standing hand to big toe pose', 'warrior pose i', 'staff pose', 'low lunge pose', 'wind release pose', 'chair pose', 'eagle pose', 'eye of the needle pose', 'supine spinal twist pose', 'corpse pose']\n\n\n['figure four pose', 'one legged mountain pose', 'five pointed star pose', 'eagle pose', 'eagle pose, repeat other side', 'corpse pose']\n\n\n['revolved high lunge pose', 'downward facing dog pose', 'firelog pose', 'lotus pose', 'sun salutation', 'thunderbolt pose', 'warrior pose i', 'sun salutation', 'thunderbolt pose', 'supine spinal twist pose', 'eye of the needle pose', 'reclined bound angle pose', 'bridge pose', 'half lord of the fishes pose', 'happy baby pose', 'half lord of the fishes pose', 'half lord of the fishes pose, repeat other side', 'supine spinal twist pose', 'high boat to low boat flow', 'seated forward bend pose', 'wind release pose', 'mountain pose', 'supine spinal twist pose', 'shoulder stretches', 'hero pose', 'sun salutation', 'chair pose', 'wind release pose', 'bow pose', 'hero pose', 'corpse pose']\n\n\n['dragonfly pose', 'reclined big toe pose', 'downward facing dog pose', 'boat pose', 'supine spinal twist pose', 'supine spinal twist pose, repeat other side', 'seated straddle pose', 'staff pose', 'firelog pose', 'seated straddle pose', 'firelog pose', 'cow face pose', 'bound angle pose', 'bound angle pose, repeat other side', 'seated forward bend pose', 'child pose', 'bound angle forward bend', 'half lord of the fishes pose', 'half lord of the fishes pose, repeat other side', 'legs up the wall pose', 'bound angle pose', 'corpse pose']\n\n\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-477-a3ec7fa47448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpeak_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_peak_poses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msecond_half\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_half\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-474-6d1bf729e961>\u001b[0m in \u001b[0;36mgenerate_class\u001b[0;34m(model, tokenizer, word_embedding, peak_pose, max_length)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# select next pose based on models probability distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprediction_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1593\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[1;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m    721\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         gen_experimental_dataset_ops.make_data_service_iterator(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3005\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3006\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MakeIterator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m         tld.op_callbacks, dataset, iterator)\n\u001b[0m\u001b[1;32m   3008\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    peak_pose = np.random.choice(possible_peak_poses)\n",
    "    second_half = generate_class(forward_model, tokenizer, embeddings, peak_pose, 40)\n",
    "    print(second_half)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = generate_class(forward_model, tokenizer, embeddings, peak_pose, \"easy pose\", 40)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_half = generate_class(forward_model, tokenizer, embeddings, peak_pose, \"corpse pose\", 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "47"
     },
     "metadata": {},
     "execution_count": 707
    }
   ],
   "source": [
    "class_length = len(first_half) + len(second_half)\n",
    "class_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoga_class = first_half + second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['easy pose',\n 'cat cow pose',\n 'wind release pose',\n 'plough pose',\n 'happy baby pose',\n 'corpse pose',\n 'legs up the wall pose',\n 'eye of the needle pose',\n 'half lord of the fishes pose',\n 'eye of the needle pose',\n 'happy baby pose',\n 'reclined big toe pose',\n 'supine spinal twist pose, repeat other side',\n 'supine spinal twist pose',\n 'bridge pose, repeat other side',\n 'bridge pose',\n 'garland pose',\n 'seated forward bend pose, repeat other side',\n 'seated forward bend pose',\n 'bound angle pose, repeat other side',\n 'bound angle pose',\n 'extended side angle pose',\n 'flamingo pose, repeat other side',\n 'flamingo pose',\n 'crane pose, repeat other side',\n 'crane pose',\n 'baby crow pose',\n 'flying pigeon pose',\n 'flying pigeon pose',\n 'wind release pose',\n 'lotus pose',\n 'happy baby pose',\n 'child pose',\n 'half lord of the fishes pose',\n 'plank pose',\n 'seated straddle pose',\n 'bound angle pose',\n 'half lord of the fishes pose',\n 'bow pose',\n 'cobra pose',\n 'cow face pose',\n 'pigeon pose',\n 'pigeon pose, repeat other side',\n 'sphinx pose',\n 'bridge pose',\n 'bridge pose, repeat other side',\n 'corpse pose']"
     },
     "metadata": {},
     "execution_count": 709
    }
   ],
   "source": [
    "yoga_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_2(model, tokenizer, word_embedding, peak_pose, stop_pose, max_length):\n",
    "\n",
    "    # generate seed text of 3 poses (as LSTM was trained on) from the input desired peak pose, by randomly selecting two of the most similar poses to the peak. \n",
    "    seed_text = [peak_pose, embeddings.most_similar(peak_pose, topn=10)[np.random.choice(range(10))][0], embeddings.most_similar(peak_pose, topn=10)[np.random.choice(range(10))][0]]\n",
    "    in_text = seed_text\n",
    "\n",
    "    # create yoga class, and make sure it includes the user's desired peak pose\n",
    "    yoga_class = list()\n",
    "    yoga_class.append(peak_pose.lower())\n",
    "\n",
    "    for i in range(max_length):\n",
    "        if not i % 2:\n",
    "            encoded = tokenizer.texts_to_sequences([in_text[::-1]])\n",
    "\n",
    "            # select next pose based on models probability distribution\n",
    "            prediction_output = model.predict(encoded)\n",
    "            yhat = np.random.choice(len(prediction_output[0]), p=prediction_output[0])\n",
    "    \n",
    "            out_word = \"\"\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            \n",
    "            if out_word != \"\":\n",
    "                if out_word == yoga_class[0]:\n",
    "                    \n",
    "\n",
    "            # append pose to current class, and update input text\n",
    "            # also add clarification text for user to repeat the pose on the other side (if its an imbalanced pose) if given two of the same pose in a row\n",
    "            if out_word != \"\":\n",
    "                if out_word == yoga_class[-1]:\n",
    "                    in_text.append(out_word)\n",
    "                    out_word += \", repeat other side\"\n",
    "                    yoga_class.append(out_word)\n",
    "                else: \n",
    "                    yoga_class.append(out_word)\n",
    "                    in_text.append(out_word)\n",
    "            if out_word == stop_pose:\n",
    "                break\n",
    "\n",
    "        # if sequence gets too long without converging to a natural ending, start over. \n",
    "        if len(yoga_class) == max_length:\n",
    "                in_text = seed_text\n",
    "                yoga_class = [peak_pose.lower()]\n",
    "    return yoga_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_2(model, tokenizer, word_embedding, peak_pose, stop_pose, max_length):\n",
    "\n",
    "    # generate seed text of 3 poses (as LSTM was trained on) from the input desired peak pose, by randomly selecting two of the most similar poses to the peak. \n",
    "    seed_text = [peak_pose, embeddings.most_similar(peak_pose, topn=10)[np.random.choice(range(10))][0], embeddings.most_similar(peak_pose, topn=10)[np.random.choice(range(10))][0]]\n",
    "    in_text = seed_text\n",
    "\n",
    "    # create yoga class, and make sure it includes the user's desired peak pose\n",
    "    yoga_class = list()\n",
    "    yoga_class.append(peak_pose.lower())\n",
    "\n",
    "    for i in range(2):\n",
    "        while True:\n",
    "            encoded = tokenizer.texts_to_sequences([in_text[::-1]])\n",
    "\n",
    "            # select next pose based on models probability distribution\n",
    "            prediction_output = model.predict(encoded)\n",
    "            yhat = np.random.choice(len(prediction_output[0]), p=prediction_output[0])\n",
    "\n",
    "            out_word = \"\"\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            \n",
    "            if out_word != \"\":\n",
    "                if out_word == yoga_class[0]:\n",
    "                    \n",
    "\n",
    "            # append pose to current class, and update input text\n",
    "            # also add clarification text for user to repeat the pose on the other side (if its an imbalanced pose) if given two of the same pose in a row\n",
    "            if out_word != \"\":\n",
    "                if out_word == yoga_class[-1]:\n",
    "                    in_text.append(out_word)\n",
    "                    out_word += \", repeat other side\"\n",
    "                    yoga_class.append(out_word)\n",
    "                else: \n",
    "                    yoga_class.append(out_word)\n",
    "                    in_text.append(out_word)\n",
    "            if out_word == stop_pose:\n",
    "                break\n",
    "\n",
    "        # if sequence gets too long without converging to a natural ending, start over. \n",
    "        if len(yoga_class) == max_length:\n",
    "                in_text = seed_text\n",
    "                yoga_class = [peak_pose.lower()]\n",
    "    return yoga_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling\n",
    "For use in flask app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"word_embeddings.pkl\", \"wb\")\n",
    "pickle.dump(embeddings, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"tokenizer.pkl\", \"wb\")\n",
    "pickle.dump(tokenizer, f)\n",
    "f.close"
   ]
  }
 ]
}